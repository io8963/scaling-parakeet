
# autobuild.py - Fixed 404 Logic

import os
import shutil
import glob
import hashlib
from typing import List, Dict, Any
from collections import defaultdict

import config
from parser import get_metadata_and_content
import generator

# --- æ£€æŸ¥ä¾èµ– ---
try:
    import pygments
except ImportError:
    pass

def hash_file(filepath: str) -> str:
    hasher = hashlib.sha256()
    try:
        with open(filepath, 'rb') as f:
            hasher.update(f.read())
        return hasher.hexdigest()[:8]
    except FileNotFoundError:
        return 'nohash'

def build_site():
    print("\n" + "="*40)
    print("   ğŸš€ STARTING BUILD PROCESS (Fix 404 List Issue & Hidden Pages)")
    print("="*40 + "\n")
    
    # -------------------------------------------------------------
    # 1. æ¸…ç†å·¥ä½œåŒº
    # -------------------------------------------------------------
    print("[1/4] Cleaning Workspace...")
    if os.path.exists(config.BUILD_DIR):
        shutil.rmtree(config.BUILD_DIR)
    
    os.makedirs(config.BUILD_DIR)
    os.makedirs(config.POSTS_OUTPUT_DIR)
    os.makedirs(config.TAGS_OUTPUT_DIR)
    os.makedirs(config.STATIC_OUTPUT_DIR)

    # -------------------------------------------------------------
    # 2. èµ„æºå¤„ç†
    # -------------------------------------------------------------
    print("\n[2/4] Processing Assets...")
    assets_dir = os.path.join(config.BUILD_DIR, 'assets')
    os.makedirs(assets_dir, exist_ok=True)
    
    if os.path.exists(config.STATIC_DIR):
        shutil.copytree(config.STATIC_DIR, config.STATIC_OUTPUT_DIR, dirs_exist_ok=True)
    
    css_source = 'assets/style.css'
    if os.path.exists(css_source):
        css_hash = hash_file(css_source)
        new_css = f"style.{css_hash}.css"
        config.CSS_FILENAME = new_css
        shutil.copy2(css_source, os.path.join(assets_dir, new_css))
    else:
        config.CSS_FILENAME = 'style.css'

    # -------------------------------------------------------------
    # 3. è§£æ Markdown (å…³é”®ä¿®å¤éƒ¨åˆ†)
    # -------------------------------------------------------------
    print("\n[3/4] Parsing Markdown Files...")
    
    md_files = glob.glob(os.path.join(config.MARKDOWN_DIR, '*.md'))
    if not md_files: md_files = glob.glob('*.md')
    
    parsed_posts = []
    tag_map = defaultdict(list)

    for md_file in md_files:
        metadata, content_md, content_html, toc_html = get_metadata_and_content(md_file)
        
        # è‡ªåŠ¨è¡¥å…¨ slug
        if 'slug' not in metadata:
            # å¦‚æœæ²¡æœ‰ slugï¼Œç”¨æ–‡ä»¶å
            filename_slug = os.path.splitext(os.path.basename(md_file))[0]
            metadata['slug'] = filename_slug

        slug = str(metadata['slug']).lower()
        file_name = os.path.basename(md_file)

        # -------------------------------------------------------
        # [å…³é”®ä¿®å¤] 404 é¡µé¢æ‹¦æˆªå™¨
        # åªè¦ slug æ˜¯ 404 æˆ–è€…æ–‡ä»¶åæ˜¯ 404.mdï¼Œç«‹å³å•ç‹¬å¤„ç†
        # -------------------------------------------------------
        if slug == '404' or file_name == '404.md':
            print(f"   -> [Special] Generating 404.html (Excluded from list)")
            
            # æ„é€ ç‰¹æ®Šæ•°æ®å¯¹è±¡
            special_post = {
                **metadata, 
                'content_markdown': content_md,
                'content_html': content_html,
                'toc_html': '', 
                'link': '404.html' # å¼ºåˆ¶æŒ‡å®šè¾“å‡ºåˆ°æ ¹ç›®å½•
            }
            # ç«‹å³ç”Ÿæˆæ–‡ä»¶
            generator.generate_post_page(special_post)
            
            # ï¼ï¼ï¼å…³é”®ï¼šcontinue è·³è¿‡ï¼Œç»å¯¹ä¸åŠ å…¥ parsed_posts åˆ—è¡¨ï¼ï¼ï¼
            continue 
        # -------------------------------------------------------

        # è¿‡æ»¤ hidden æ ‡è®°çš„æ–‡ç«  (åŒé‡ä¿é™©)
        if metadata.get('hidden') is True: 
            # å¦‚æœæ˜¯ hiddenï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯ about é¡µé¢
            if slug == 'about' or file_name == config.ABOUT_PAGE:
                 special_post = { **metadata, 'content_html': content_html, 'toc_html': '', 'link': 'about.html' }
                 generator.generate_page_html(special_post['content_html'], special_post['title'], 'about', 'about.html')
                 print(f"   -> [Special] Generating about.html (Hidden)")
            
            # Hidden é¡µé¢ä¸åŠ å…¥åˆ—è¡¨
            continue 

        # æ£€æŸ¥æ™®é€šæ–‡ç« çš„å¿…è¦å­—æ®µ
        if not all(k in metadata for k in ['date', 'title']): 
            continue
            
        # æ™®é€šæ–‡ç« å¤„ç†
        post = {
            **metadata, 
            'content_markdown': content_md,
            'content_html': content_html,
            'toc_html': toc_html,
            'link': os.path.join(config.POSTS_DIR_NAME, f"{slug}.html").replace('\\', '/')
        }
        
        # æ”¶é›†æ ‡ç­¾
        for tag_data in post.get('tags', []):
            tag_map[tag_data['name']].append(post)
            
        parsed_posts.append(post)

    # æ’åº
    final_parsed_posts = sorted(parsed_posts, key=lambda p: p['date'], reverse=True)
    print(f"   -> Successfully parsed {len(final_parsed_posts)} blog posts.")

    # -------------------------------------------------------------
    # 4. ç”Ÿæˆ HTML
    # -------------------------------------------------------------
    print("\n[4/4] Generating HTML...")
    
    # ç”Ÿæˆæ™®é€šæ–‡ç« è¯¦æƒ…é¡µ
    for post in final_parsed_posts:
        generator.generate_post_page(post)
    
    # ç”Ÿæˆåˆ—è¡¨é¡µ (æ­¤æ—¶ final_parsed_posts é‡Œç»å¯¹æ²¡æœ‰ 404/hidden)
    generator.generate_index_html(final_parsed_posts)
    generator.generate_archive_html(final_parsed_posts)
    generator.generate_tags_list_html(tag_map)

    # ç”Ÿæˆæ ‡ç­¾é¡µ
    for tag, posts in tag_map.items():
        sorted_tag = sorted(posts, key=lambda p: p['date'], reverse=True)
        generator.generate_tag_page(tag, sorted_tag)

    generator.generate_robots_txt()
    
    # Sitemap å’Œ RSS ä½¿ç”¨ç»è¿‡è¿‡æ»¤å’Œæ’åºçš„åˆ—è¡¨
    with open(os.path.join(config.BUILD_DIR, config.SITEMAP_FILE), 'w', encoding='utf-8') as f:
        f.write(generator.generate_sitemap(final_parsed_posts))
    with open(os.path.join(config.BUILD_DIR, config.RSS_FILE), 'w', encoding='utf-8') as f:
        f.write(generator.generate_rss(final_parsed_posts))
        
    print("\nâœ… BUILD COMPLETE")

if __name__ == '__main__':
    build_site()
