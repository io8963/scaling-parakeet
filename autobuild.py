# autobuild.py

import os
import shutil
import glob
import hashlib
from typing import List, Dict, Any
from collections import defaultdict

# å¯¼å…¥åˆ†ç¦»åçš„æ¨¡å—
import config
from parser import get_metadata_and_content, tag_to_slug 
import generator

# --- è‡ªæ£€ç¯èŠ‚ï¼šæ£€æŸ¥ Pygments æ˜¯å¦å®‰è£… ---
try:
    import pygments
    # print(f"CHECK: Pygments found (version {pygments.__version__}).")
except ImportError:
    print("!!!! CRITICAL WARNING: Pygments library is NOT installed. Code blocks will NOT be highlighted. !!!!")

# ------------------------------------


# --- è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—æ–‡ä»¶å“ˆå¸Œ ---
def hash_file(filepath: str) -> str:
    """è®¡ç®—æ–‡ä»¶çš„ SHA256 å“ˆå¸Œå€¼çš„å‰8ä½"""
    hasher = hashlib.sha256()
    try:
        with open(filepath, 'rb') as f:
            buf = f.read()
            hasher.update(buf)
        return hasher.hexdigest()[:8]
    except FileNotFoundError:
        return 'nohash'


# --- ä¸»æ„å»ºå‡½æ•° ---

def build_site():
    """æ¸…ç†ã€è§£æã€ç”Ÿæˆæ•´ä¸ªç½‘ç«™ã€‚"""
    
    print("\n========================================")
    print("   Starting Build Process... ğŸš€")
    print("========================================\n")
    
    # -------------------------------------------------------------
    # 1. æ·±åº¦æ¸…ç† (Deep Clean)
    # æ ¸å¿ƒé€»è¾‘ï¼šé™¤äº† 'static' å’Œ 'media' è¿™ç§å¤§æ–‡ä»¶å¤¹å¤–ï¼Œ
    # å¼ºåˆ¶åˆ é™¤ posts, tags, assets ä»¥åŠæ ¹ç›®å½•ä¸‹çš„ html/xml æ–‡ä»¶ã€‚
    # è¿™ç¡®ä¿äº†å¦‚æœ Markdown è¢«åˆ é™¤äº†ï¼Œå¯¹åº”çš„ HTML ä¹Ÿä¼šå½»åº•æ¶ˆå¤±ã€‚
    # -------------------------------------------------------------
    print("--- 1. Cleaning up old build directory ---")
    
    if os.path.exists(config.BUILD_DIR):
        # å®šä¹‰éœ€è¦ã€ä¿ç•™ã€‘çš„æ–‡ä»¶å¤¹ï¼ˆé¿å…é‡å¤æ‹·è´å¤§æ–‡ä»¶ï¼‰
        # æ³¨æ„ï¼š.git å’Œ CNAME æ˜¯ä¸ºäº† GitHub Pages éƒ¨ç½²ä¿ç•™çš„
        keep_list = [config.STATIC_DIR, config.MEDIA_DIR, '.git', 'CNAME']
        
        for item in os.listdir(config.BUILD_DIR):
            if item in keep_list:
                continue
            
            item_path = os.path.join(config.BUILD_DIR, item)
            try:
                if os.path.isdir(item_path):
                    shutil.rmtree(item_path) # é€’å½’åˆ é™¤æ–‡ä»¶å¤¹ (å¦‚ posts, tags, assets)
                    print(f"   [Deleted Dir]  {item}/")
                else:
                    os.remove(item_path)     # åˆ é™¤æ–‡ä»¶ (å¦‚ index.html, archive.html)
                    # print(f"   [Deleted File] {item}")
            except Exception as e:
                print(f"   Error deleting {item}: {e}")
    else:
        os.makedirs(config.BUILD_DIR, exist_ok=True)
    
    # é‡å»ºåŸºç¡€ç›®å½•ç»“æ„
    os.makedirs(config.POSTS_OUTPUT_DIR, exist_ok=True)
    os.makedirs(config.TAGS_OUTPUT_DIR, exist_ok=True)
    os.makedirs(config.STATIC_OUTPUT_DIR, exist_ok=True) 
    
    # -------------------------------------------------------------
    # 2. èµ„æºå¤„ç† (Assets & CSS)
    # æ¯æ¬¡éƒ½é‡æ–°å¤„ç† CSSï¼Œç¡®ä¿ä¿®æ”¹æ ·å¼åå“ˆå¸Œå€¼æ›´æ–°
    # -------------------------------------------------------------
    print("\n--- 2. Processing Assets ---")
    assets_dir = os.path.join(config.BUILD_DIR, 'assets')
    os.makedirs(assets_dir, exist_ok=True)
    
    # å¤åˆ¶é™æ€æ–‡ä»¶å¤¹ (å¦‚æœä¹‹å‰ä¿ç•™äº†ï¼Œè¿™é‡Œä¼šè‡ªåŠ¨è·³è¿‡æˆ–è¦†ç›–)
    if os.path.exists(config.STATIC_DIR):
        # dirs_exist_ok=True å…è®¸è¦†ç›–
        shutil.copytree(config.STATIC_DIR, config.STATIC_OUTPUT_DIR, dirs_exist_ok=True)
    
    # å¤„ç† CSS å“ˆå¸Œ
    css_source_path = 'assets/style.css'
    if os.path.exists(css_source_path):
        css_hash = hash_file(css_source_path)
        new_css_filename = f"style.{css_hash}.css"
        
        # æ›´æ–°å…¨å±€é…ç½®ä¸­çš„æ–‡ä»¶åï¼Œä»¥ä¾¿æ¨¡æ¿ä½¿ç”¨
        config.CSS_FILENAME = new_css_filename
        
        css_dest_path = os.path.join(assets_dir, new_css_filename)
        shutil.copy2(css_source_path, css_dest_path)
        print(f"   [CSS Generated] {new_css_filename}")
    else:
        config.CSS_FILENAME = 'style.css'
        print("   [Warning] assets/style.css not found.")

    # -------------------------------------------------------------
    # 3. è§£æ Markdown (Parsing)
    # -------------------------------------------------------------
    print("\n--- 3. Parsing Markdown Files ---")
    
    md_files = glob.glob(os.path.join(config.MARKDOWN_DIR, '*.md'))
    if not md_files:
        # å…¼å®¹æ ¹ç›®å½•æ¨¡å¼
        md_files = glob.glob('*.md')
    
    if not md_files:
        print("   [Error] No Markdown files found. Aborting.")
        return

    parsed_posts: List[Dict[str, Any]] = []
    tag_map = defaultdict(list)
    
    for md_file in md_files:
        # è§£ææ–‡ä»¶
        metadata, content_markdown, content_html, toc_html = get_metadata_and_content(md_file)
        
        # è·³è¿‡æ ‡è®°ä¸º hidden: true çš„æ–‡ç«  (ç”¨äºè‰ç¨¿æˆ–ç‰¹æ®Šé¡µé¢)
        if metadata.get('hidden') is True:
            # print(f"   [Skip] Hidden file: {os.path.basename(md_file)}")
            continue

        # æ£€æŸ¥å¿…è¦å…ƒæ•°æ®
        if not all(k in metadata for k in ['date', 'title', 'slug']):
            print(f"   [Skip] Missing metadata in: {os.path.basename(md_file)}")
            continue
            
        post: Dict[str, Any] = {
            **metadata, 
            'content_markdown': content_markdown,
            'content_html': content_html,
            'toc_html': toc_html,
        }
        
        # æ„å»ºé“¾æ¥
        post_link = os.path.join(config.POSTS_DIR_NAME, f"{post['slug']}.html")
        post['link'] = post_link.replace('\\', '/') # ä¿®å¤ Windows è·¯å¾„åˆ†éš”ç¬¦
        
        # æ”¶é›†æ ‡ç­¾
        for tag_data in post.get('tags', []):
            tag_map[tag_data['name']].append(post)
            
        parsed_posts.append(post)

    # æ’åºï¼šæŒ‰æ—¥æœŸé™åº
    final_parsed_posts = sorted(parsed_posts, key=lambda p: p['date'], reverse=True)
    print(f"   [OK] Successfully parsed {len(final_parsed_posts)} articles.")

    # -------------------------------------------------------------
    # 4. ç”Ÿæˆ HTML é¡µé¢ (Generating)
    # -------------------------------------------------------------
    print("\n--- 4. Generating HTML Pages ---")
    
    # ç”Ÿæˆæ–‡ç« è¯¦æƒ…é¡µ
    for post in final_parsed_posts:
        generator.generate_post_page(post)
    
    # ç”Ÿæˆåˆ—è¡¨é¡µ (é¦–é¡µ, å½’æ¡£, æ ‡ç­¾äº‘)
    # æ­¤æ—¶ä¼ å…¥çš„ final_parsed_posts å·²ç»æ˜¯ã€ä¸åŒ…å«ã€‘å·²åˆ é™¤æ–‡ä»¶çš„æœ€æ–°åˆ—è¡¨
    generator.generate_index_html(final_parsed_posts)
    generator.generate_archive_html(final_parsed_posts)
    generator.generate_tags_list_html(tag_map)

    # ç”Ÿæˆæ ‡ç­¾è¯¦æƒ…é¡µ
    for tag, posts in tag_map.items():
        sorted_tag_posts = sorted(posts, key=lambda p: p['date'], reverse=True)
        generator.generate_tag_page(tag, sorted_tag_posts)

    # ç”Ÿæˆç‰¹æ®Šæ–‡ä»¶
    generator.generate_robots_txt()
    
    # Sitemap & RSS
    sitemap_content = generator.generate_sitemap(final_parsed_posts)
    with open(os.path.join(config.BUILD_DIR, config.SITEMAP_FILE), 'w', encoding='utf-8') as f:
        f.write(sitemap_content)
        
    rss_xml_content = generator.generate_rss(final_parsed_posts)
    with open(os.path.join(config.BUILD_DIR, config.RSS_FILE), 'w', encoding='utf-8') as f:
        f.write(rss_xml_content)
        
    print(f"\nâœ… Site built successfully in '{config.BUILD_DIR}' directory.")
    print(f"   Total Posts: {len(final_parsed_posts)}")
    print("========================================\n")


if __name__ == '__main__':
    build_site()
