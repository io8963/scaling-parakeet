# autobuild.py

import os
import shutil
import glob
from typing import List, Dict, Any
from collections import defaultdict

# å¯¼å…¥åˆ†ç¦»åçš„æ¨¡å—
import config
# å…³é”®ä¿®æ­£ï¼šç¡®ä¿ parser æ¨¡å—è¢«æ­£ç¡®å¯¼å…¥
from parser import get_metadata_and_content, tag_to_slug 
import generator

# --- ä¸»æ„å»ºå‡½æ•° ---

def build_site():
    """æ¸…ç†ã€è§£æã€ç”Ÿæˆæ•´ä¸ªç½‘ç«™ã€‚"""
    
    print("--- 1. æ¸…ç†å’Œå‡†å¤‡ç›®å½• ---")
    
    # ç¡®ä¿æ„å»ºç›®å½•å¹²å‡€
    if os.path.exists(config.BUILD_DIR):
        print(f"Cleaning up old build directory: {config.BUILD_DIR}")
        shutil.rmtree(config.BUILD_DIR)
    
    # åˆ›å»ºæ‰€æœ‰å¿…éœ€çš„ç›®å½•
    os.makedirs(config.POSTS_OUTPUT_DIR, exist_ok=True)
    os.makedirs(config.TAGS_OUTPUT_DIR, exist_ok=True)
    
    # å¤åˆ¶é™æ€æ–‡ä»¶
    # æ³¨æ„: è¿™é‡Œå‡å®š assets å’Œ static ç›®å½•ä½äº autobuild.py æ—è¾¹
    for src_dir, dest_dir in [('assets', config.BUILD_DIR), ('static', config.STATIC_OUTPUT_DIR), ('media', config.MEDIA_OUTPUT_DIR)]:
        if os.path.exists(src_dir):
            try:
                # ç›®æ ‡ç›®å½•å·²ç»å­˜åœ¨ï¼Œæ‰€ä»¥æˆ‘ä»¬åªå¤åˆ¶å†…å®¹
                if src_dir == 'assets': # å¤åˆ¶ assets åˆ° _site æ ¹ç›®å½•
                    shutil.copytree(src_dir, os.path.join(config.BUILD_DIR, src_dir), dirs_exist_ok=True)
                else:
                    shutil.copytree(src_dir, dest_dir, dirs_exist_ok=True)
                print(f"SUCCESS: Copied {src_dir} to {os.path.basename(dest_dir)}")
            except Exception as e:
                print(f"Error copying {src_dir}: {e}")
        else:
            print(f"Warning: Source directory '{src_dir}' not found.")
            
    print("--- 2. è§£æ Markdown æ–‡ä»¶ ---")
    
    # æŸ¥æ‰¾æ‰€æœ‰ Markdown æ–‡ä»¶
    # æŸ¥æ‰¾æ‰€æœ‰ .md æ–‡ä»¶ï¼ŒåŒ…æ‹¬ MD_DIR ç›®å½•ä¸‹çš„æ–‡ä»¶
    markdown_files = glob.glob(os.path.join(config.MD_DIR, '**', '*.md'), recursive=True)
    
    if not markdown_files:
        print("Warning: No Markdown files found. Site will be built without content.")

    parsed_posts = []
    tag_map = defaultdict(list) # ç”¨äºæ ‡ç­¾é¡µç”Ÿæˆ
    
    for md_file in markdown_files:
        post_data = {}
        
        # å…³é”®ä¿®æ­£ï¼šæ¥æ”¶ parser.py è¿”å›çš„å…¨éƒ¨å››ä¸ªå€¼
        metadata, content_markdown, content_html, toc_html = get_metadata_and_content(md_file)
        
        # è·³è¿‡æ²¡æœ‰æ ‡é¢˜çš„æ–‡ç« ï¼Œæˆ–è€…è·³è¿‡è®¾ç½®äº† draft: true çš„æ–‡ç« 
        if not metadata.get('title') or metadata.get('draft') is True:
            # print(f"Skipping draft or untitled post: {md_file}") # è°ƒè¯•è¡Œï¼Œå¯ç§»é™¤
            continue
        
        # --- æ ¸å¿ƒæ•°æ®æ˜ å°„ ---
        
        # 1. æ ‡é¢˜å’Œå†…å®¹
        post_data.update(metadata)
        post_data['content_markdown'] = content_markdown
        post_data['content_html'] = content_html
        # å…³é”®ä¿®æ­£ï¼šå­˜å‚¨ TOC HTML
        post_data['toc_html'] = toc_html
        
        # 2. ç”Ÿæˆ slug
        # ä¼˜å…ˆä½¿ç”¨ metadata ä¸­çš„ slugï¼Œå¦åˆ™ä½¿ç”¨æ–‡ä»¶åä½œä¸º slug
        base_name = os.path.splitext(os.path.basename(md_file))[0]
        post_data['slug'] = metadata.get('slug', base_name)
        
        # 3. å¤„ç†åˆ†ç±» (å¯é€‰)
        # æš‚æ—¶ä¸æ”¯æŒå¤æ‚çš„åˆ†ç±»ï¼Œä»…æ”¯æŒ posts/slug.html ç»“æ„
        
        # 4. å­˜å‚¨åˆ°å…¨å±€åˆ—è¡¨
        parsed_posts.append(post_data)
        
        # 5. å»ºç«‹æ ‡ç­¾æ˜ å°„
        for tag_info in post_data['tags']:
            # tag_info æ˜¯ {'name': '...', 'slug': '...'} ç»“æ„
            tag_map[tag_info['slug']].append(post_data)


    # æŒ‰æ—¥æœŸé™åºæ’åˆ—æ‰€æœ‰æ–‡ç« 
    final_parsed_posts = sorted(
        parsed_posts, 
        key=lambda p: p['date'], 
        reverse=True
    )
    
    print(f"SUCCESS: Parsed {len(final_parsed_posts)} Markdown files.")
    
    print("--- 3. ç”Ÿæˆæ–‡ç« è¯¦æƒ…é¡µ ---")
    
    # 3a. ç”Ÿæˆæ¯ä¸€ç¯‡æ–‡ç« çš„ HTML æ–‡ä»¶
    for post in final_parsed_posts:
        generator.generate_post_html(post)
        
    print(f"Generated {len(final_parsed_posts)} post detail pages.")
        
    print("--- 4. ç”Ÿæˆé€šç”¨é¡µé¢å’Œåˆ—è¡¨é¡µ ---")
    
    # 4a. é¦–é¡µ (index.html) - åªæ˜¾ç¤ºæœ€æ–°çš„å‡ ç¯‡æ–‡ç« 
    generator.generate_index_html(final_parsed_posts)
    
    # 4b. å½’æ¡£é¡µ (archive.html) - æ˜¾ç¤ºæ‰€æœ‰æ–‡ç« 
    generator.generate_archive_html(final_parsed_posts)
    
    # 4c. å…³äºé¡µ (about.html) - ç‹¬ç«‹æ–‡ç« 
    # å‡å®š about.md æ€»æ˜¯å­˜åœ¨ (åœ¨ MD_DIR æ ¹ç›®å½•)
    about_md_path = os.path.join(config.MD_DIR, 'about.md')
    if os.path.exists(about_md_path):
        # å…³é”®ä¿®æ­£ï¼šæ¥æ”¶ parser.py è¿”å›çš„å…¨éƒ¨å››ä¸ªå€¼
        about_meta, about_md, about_html, about_toc = get_metadata_and_content(about_md_path)
        # å°† about.md è§†ä¸ºä¸€ä¸ªç‰¹æ®Šçš„ post å¯¹è±¡
        about_post = {
            'title': about_meta.get('title', 'å…³äº'),
            'content_html': about_html,
            'canonical_url': generator.make_internal_url(config.ABOUT_FILE), # ä¿®æ­£: about é¡µé¢ä½¿ç”¨è‡ªèº«çš„ url
            # MODIFIED: ä¼ é€’ toc_html ä»¥é˜² about.md ä¸­æœ‰ç›®å½•
            'toc_html': about_toc
        }
        generator.generate_about_html(about_post)
        print(f"Generated {config.ABOUT_FILE}.")
    else:
        print(f"Warning: {config.MD_DIR}/about.md not found. Skipping about page generation.")

    # 4d. æ ‡ç­¾é¡µ
    
    # 4d-1. ç”Ÿæˆæ‰€æœ‰æ ‡ç­¾çš„åˆ—è¡¨é¡µ (tags.html)
    generator.generate_tags_list_html(tag_map)

    # 4d-2. ä¸ºæ¯ä¸ªæ ‡ç­¾ç”Ÿæˆå•ç‹¬é¡µé¢
    for tag, posts in tag_map.items():
        # æŒ‰æ—¥æœŸæ’åºè¯¥æ ‡ç­¾ä¸‹çš„æ–‡ç« 
        sorted_tag_posts = sorted(
            posts, 
            key=lambda p: p['date'], 
            reverse=True
        )
        generator.generate_tag_page(tag, sorted_tag_posts)
        
    print(f"Generated {len(tag_map)} tag pages.")


    print("--- 5. ç”Ÿæˆ XML æ–‡ä»¶ ---")
    
    # 5a. robots.txt
    generator.generate_robots_txt()
    
    # 5b. sitemap.xml
    sitemap_content = generator.generate_sitemap(final_parsed_posts)
    try:
        output_path = os.path.join(config.BUILD_DIR, config.SITEMAP_FILE)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(sitemap_content)
        print(f"SUCCESS: Generated {config.SITEMAP_FILE}.")
    except Exception as e:
        print(f"Error generating sitemap.xml: {type(e).__name__}: {e}")
        
    # 5c. rss.xml
    rss_xml_content = generator.generate_rss(final_parsed_posts)
    try:
        output_path = os.path.join(config.BUILD_DIR, config.RSS_FILE)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(rss_xml_content)
        print(f"SUCCESS: Generated {config.RSS_FILE}.")
    except Exception as e:
        print(f"Error generating rss.xml: {type(e).__name__}: {e}")

    
    print("\\n--- ğŸ‰ ç½‘ç«™æ„å»ºå®Œæˆï¼ ---")
    print(f"è¾“å‡ºç›®å½•: {config.BUILD_DIR}")


if __name__ == '__main__':
    build_site()
