# autobuild.py - Incremental Build Enabled

import os
import shutil
import glob
import hashlib
from typing import List, Dict, Any, Set
from collections import defaultdict
from datetime import datetime, timezone, timedelta 
import subprocess # ç”¨äºŽæ‰§è¡Œ Git å‘½ä»¤
import shlex      # ç”¨äºŽå®‰å…¨å¤„ç†å‘½ä»¤å­—ç¬¦ä¸²
# [æ–°å¢ž]
import json
from typing import Dict, Any

import config
from parser import get_metadata_and_content
import generator

# [æ–°å¢ž] å®šä¹‰æ¸…å•æ–‡ä»¶è·¯å¾„
MANIFEST_FILE = os.path.join(os.path.dirname(__file__), '.build_manifest.json')

# [æ–°å¢ž] Manifest è¾…åŠ©å‡½æ•°
def load_manifest() -> Dict[str, Any]:
    """åŠ è½½ä¸Šä¸€æ¬¡çš„æž„å»ºæ¸…å•æ–‡ä»¶ã€‚"""
    try:
        with open(MANIFEST_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        # å¦‚æžœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯ï¼Œè¿”å›žç©ºæ¸…å•
        return {}

def save_manifest(manifest: Dict[str, Any]):
    """ä¿å­˜å½“å‰çš„æž„å»ºæ¸…å•æ–‡ä»¶ã€‚"""
    try:
        with open(MANIFEST_FILE, 'w', encoding='utf-8') as f:
            # ä½¿ç”¨ indent=4 æé«˜å¯è¯»æ€§
            json.dump(manifest, f, ensure_ascii=False, indent=4)
    except IOError as e:
        print(f"è­¦å‘Šï¼šæ— æ³•å†™å…¥æž„å»ºæ¸…å•æ–‡ä»¶ {MANIFEST_FILE}: {e}")

def get_full_content_hash(filepath: str) -> str:
    """è®¡ç®—æ–‡ä»¶çš„å®Œæ•´ SHA256 å“ˆå¸Œå€¼ã€‚ç”¨äºŽ Manifestã€‚"""
    h = hashlib.sha256()
    try:
        with open(filepath, 'rb') as file:
            while True:
                chunk = file.read(4096)
                if not chunk:
                    break
                h.update(chunk)
    except IOError:
        return ""
    return h.hexdigest()

# [æ–°å¢ž] å®šä¹‰ UTC+8 æ—¶åŒºä¿¡æ¯
TIMEZONE_OFFSET = timedelta(hours=8)
TIMEZONE_INFO = timezone(TIMEZONE_OFFSET)

# --- æ£€æŸ¥ä¾èµ– ---
try:
    import pygments
except ImportError:
    pass

def hash_file(filepath: str) -> str:
    """è®¡ç®—æ–‡ä»¶çš„ SHA256 å“ˆå¸Œå€¼å‰ 8 ä½ã€‚ç”¨äºŽ CSS æ–‡ä»¶åã€‚"""
    hasher = hashlib.sha256()
    try:
        with open(filepath, 'rb') as f:
            hasher.update(f.read())
        return hasher.hexdigest()[:8]
    except FileNotFoundError:
        return 'nohash'

# [æœ€ç»ˆä¿®å¤ FUNCTION] èŽ·å–æ–‡ä»¶çš„æœ€åŽä¿®æ”¹æ—¶é—´ (å¼ºåˆ¶ä½¿ç”¨ Git Author Time) å¹¶æ ¼å¼åŒ–ä¸º UTC+8
def format_file_mod_time(filepath: str) -> str:
    """èŽ·å–æ–‡ä»¶çš„æœ€åŽä¿®æ”¹æ—¶é—´ (å¼ºåˆ¶ä½¿ç”¨ Git Author Time) å¹¶æ ¼å¼åŒ–ä¸ºä¸­æ–‡æž„å»ºæ—¶é—´ (UTC+8)ã€‚"""
    
    # å°è¯•èŽ·å– Git æœ€åŽæäº¤æ—¶é—´ (ä½¿ç”¨ Author Date %aIï¼Œé€šå¸¸æ›´æŽ¥è¿‘å®žé™…ä¿®æ”¹æ—¥æœŸ)
    try:
        # ä½¿ç”¨ subprocess.run ä»£æ›¿ os.popenï¼Œæä¾›æ›´ç²¾ç»†çš„é”™è¯¯æŽ§åˆ¶
        git_command = ['git', 'log', '-1', '--pretty=format:%aI', '--', filepath]
        
        # check=False: ä¸åœ¨å‘½ä»¤å¤±è´¥æ—¶æŠ›å¼‚å¸¸ï¼Œæˆ‘ä»¬æ‰‹åŠ¨æ£€æŸ¥ returncode
        result = subprocess.run(git_command, capture_output=True, text=True, cwd=os.getcwd())
        
        if result.returncode != 0:
             # å¦‚æžœ Git å‘½ä»¤æ‰§è¡Œå¤±è´¥ (å¦‚ï¼šæ–‡ä»¶ä¸å­˜åœ¨, ä¸åœ¨ Git ä»“åº“, æˆ–æ–‡ä»¶æœªè¿½è¸ª)
             # æ‰“å°é”™è¯¯ä¿¡æ¯è¾…åŠ©æŽ’æŸ¥
             print(f"   [WARNING] Git failed for {filepath}: {result.stderr.strip()}")
             raise Exception("Git command failed or file is untracked.")

        git_time_str = result.stdout.strip()
        
        if git_time_str:
            # è§£æž ISO æ—¶é—´å­—ç¬¦ä¸²ï¼Œdatetime.fromisoformat ä¼šæ­£ç¡®å¤„ç†æ—¶åŒºåç§»
            try:
                mtime_dt_tz = datetime.fromisoformat(git_time_str)
            except ValueError:
                # å†æ¬¡å°è¯•å¤„ç†å¸¸è§çš„æ—¶åŒºæ ¼å¼é—®é¢˜
                if git_time_str.endswith('Z'):
                    git_time_str = git_time_str.replace('Z', '+00:00')
                mtime_dt_tz = datetime.fromisoformat(git_time_str)
            
            # è½¬æ¢ä¸º UTC+8 (ä¿è¯æ˜¾ç¤ºæ—¶åŒºä¸€è‡´æ€§)
            mtime_dt_utc8 = mtime_dt_tz.astimezone(TIMEZONE_INFO)
            
            return f"æœ¬æ–‡æž„å»ºæ—¶é—´: {mtime_dt_utc8.strftime('%Y-%m-%d %H:%M:%S')} (UTC+8 - Git)"

        # Git æˆåŠŸè¿è¡Œä½†æ–‡ä»¶æœªè¢«è¿½è¸ª/æ— åŽ†å²è®°å½•ï¼Œè¿›å…¥å›žé€€
        raise Exception("Git time not found (no history).") 

    except Exception as e:
        # æ‰€æœ‰ Git ç›¸å…³é”™è¯¯çš„å›žé€€é€»è¾‘
        # å¼ºåˆ¶ä½¿ç”¨å½“å‰çš„æž„å»ºæ—¶é—´ä½œä¸ºæ–‡ç« çš„ fallback æ—¶é—´ã€‚
        now_utc = datetime.now(timezone.utc)
        now_utc8 = now_utc.astimezone(TIMEZONE_INFO)
        # æ ‡è®°ä¸º Fallbackï¼Œè¡¨ç¤ºæœªèƒ½èŽ·å–åˆ°åŽ†å²ä¿®æ”¹æ—¶é—´ï¼Œè¯¥æ—¶é—´æ˜¯å½“å‰æž„å»ºæ—¶é—´
        return f"æœ¬æ–‡æž„å»ºæ—¶é—´: {now_utc8.strftime('%Y-%m-%d %H:%M:%S')} (UTC+8 - Fallback)"


def build_site():
    print("\n" + "="*40)
    print("   ðŸš€ STARTING BUILD PROCESS (Incremental Build Enabled)")
    print("="*40 + "\n")
    
    # -------------------------------------------------------------
    # 1. å‡†å¤‡å·¥ä½œ & å¢žé‡æž„å»ºåˆå§‹åŒ–
    # -------------------------------------------------------------
    print("[1/4] Preparing build directory and loading manifest...")
    
    # [MODIFIED] ç§»é™¤ shutil.rmtree(config.BUILD_DIR)ï¼Œæ”¹ä¸ºå¢žé‡å¤„ç†
    # ç¡®ä¿æ‰€æœ‰ç›®å½•å­˜åœ¨ (exist_ok=True å®žçŽ°å¢žé‡)
    os.makedirs(config.BUILD_DIR, exist_ok=True) 
    os.makedirs(config.POSTS_OUTPUT_DIR, exist_ok=True)
    os.makedirs(config.TAGS_OUTPUT_DIR, exist_ok=True)
    os.makedirs(config.STATIC_OUTPUT_DIR, exist_ok=True)

    # åŠ è½½ä¸Šæ¬¡çš„æž„å»ºæ¸…å•
    old_manifest = load_manifest()
    new_manifest = {}
    
    # å­˜å‚¨éœ€è¦é‡æ–°ç”Ÿæˆ HTML çš„æ–‡ç« å¯¹è±¡
    posts_to_build: List[Dict[str, Any]] = [] 
    # æ ‡å¿—ä½ï¼šæ–‡ç« é›†åˆä¿¡æ¯æ˜¯å¦å˜åŒ– (å½±å“åˆ—è¡¨é¡µã€RSSã€Sitemap)
    posts_data_changed = False      
    
    # -------------------------------------------------------------
    # 2. èµ„æºå¤„ç†
    # -------------------------------------------------------------
    print("\n[2/4] Processing Assets...")
    assets_dir = os.path.join(config.BUILD_DIR, 'assets')
    os.makedirs(assets_dir, exist_ok=True)
    
    # å¤åˆ¶é™æ€æ–‡ä»¶
    if os.path.exists(config.STATIC_DIR):
        shutil.copytree(config.STATIC_DIR, config.STATIC_OUTPUT_DIR, dirs_exist_ok=True)
    
    # CSS å“ˆå¸Œå’Œå¤åˆ¶ (ä¿æŒä¸å˜)
    css_source = 'assets/style.css'
    if os.path.exists(css_source):
        css_hash = hash_file(css_source)
        new_css = f"style.{css_hash}.css"
        config.CSS_FILENAME = new_css
        shutil.copy2(css_source, os.path.join(assets_dir, new_css))
    else:
        config.CSS_FILENAME = 'style.css'

    # -------------------------------------------------------------
    # 3. è§£æž Markdown (åº”ç”¨å¢žé‡é€»è¾‘)
    # -------------------------------------------------------------
    print("\n[3/4] Parsing Markdown Files...")
    
    # å…¼å®¹å¤„ç†ï¼šç¡®ä¿èƒ½æ‰¾åˆ° Markdown æ–‡ä»¶
    md_files = glob.glob(os.path.join(config.MARKDOWN_DIR, '*.md'))
    if not md_files: md_files = glob.glob('*.md')
    
    parsed_posts = []
    tag_map = defaultdict(list)
    
    # [æ–°å¢ž] è¿½è¸ªå½“å‰æ‰¾åˆ°çš„æ‰€æœ‰ Markdown æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„
    source_md_paths: Set[str] = set()

    for md_file in md_files:
        # ä½¿ç”¨ç›¸å¯¹äºŽé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„ä½œä¸º Manifest Key
        relative_path = os.path.relpath(md_file, os.path.dirname(__file__)).replace('\\', '/')
        source_md_paths.add(relative_path)
        
        # 1. è®¡ç®—å½“å‰å“ˆå¸Œ
        current_hash = get_full_content_hash(md_file)
        
        # 2. ä»Žæ—§æ¸…å•ä¸­æŸ¥æ‰¾çŠ¶æ€
        old_item = old_manifest.get(relative_path, {})
        old_hash = old_item.get('hash')
        old_link = old_item.get('link')

        # 3. åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°ç”Ÿæˆ HTML (å†…å®¹å“ˆå¸Œå˜åŠ¨, æˆ–æ¸…å•ä¸­æ²¡æœ‰ä¸Šæ¬¡çš„é“¾æŽ¥)
        needs_full_build = (current_hash != old_hash) or (old_link is None)
        
        if needs_full_build:
            print(f"   -> [CHANGED/NEW] {os.path.basename(md_file)}")
            posts_data_changed = True
        else:
            print(f"   -> [SKIPPED HTML] {os.path.basename(md_file)}")

        # 4. è§£æžå†…å®¹ (æ— è®ºæ˜¯å¦å˜åŠ¨ï¼Œéƒ½éœ€è¦è§£æžå…ƒæ•°æ®æ¥æž„å»ºåˆ—è¡¨é¡µ)
        metadata, content_md, content_html, toc_html = get_metadata_and_content(md_file)
        
        # è‡ªåŠ¨è¡¥å…¨ slug
        if 'slug' not in metadata:
            filename_slug = os.path.splitext(os.path.basename(md_file))[0]
            metadata['slug'] = filename_slug

        slug = str(metadata['slug']).lower()
        file_name = os.path.basename(md_file)
        
        mod_time_cn = format_file_mod_time(md_file)
        
        # -------------------------------------------------------
        # 404/Hidden Pages Logic (ç‰¹æ®Šé¡µé¢å¤„ç†)
        # -------------------------------------------------------
        if slug == '404' or file_name == '404.md':
            # 404 é¡µé¢ç«‹å³ç”Ÿæˆï¼Œå¹¶æ›´æ–°æ¸…å•
            special_post = { 
                **metadata, 'content_html': content_html, 'toc_html': '', 
                'link': '404.html', 'footer_time_info': mod_time_cn
            }
            generator.generate_post_page(special_post)
            new_manifest[relative_path] = {'hash': current_hash, 'link': '404.html'}
            continue 

        if metadata.get('hidden') is True: 
            if slug == 'about' or file_name == config.ABOUT_PAGE:
                 # About é¡µé¢ç«‹å³ç”Ÿæˆï¼Œå¹¶æ›´æ–°æ¸…å•
                 special_post = { 
                     **metadata, 'content_html': content_html, 'toc_html': '', 
                     'link': 'about.html', 'footer_time_info': mod_time_cn
                 }
                 generator.generate_page_html(
                     special_post['content_html'], special_post['title'], 
                     'about', 'about.html', special_post['footer_time_info']
                 )
                 print(f"   -> [Special] Generating about.html (Hidden)")
            
            # Hidden é¡µé¢ä¸åŠ å…¥åˆ—è¡¨
            new_manifest[relative_path] = {'hash': current_hash, 'link': 'hidden'}
            continue 

        # æ£€æŸ¥æ™®é€šæ–‡ç« çš„å¿…è¦å­—æ®µ
        if not all(k in metadata for k in ['date', 'title']): 
            continue
            
        # æ™®é€šæ–‡ç« å¤„ç†
        post_link = os.path.join(config.POSTS_DIR_NAME, f"{slug}.html").replace('\\', '/')
        post = {
            **metadata, 
            'content_markdown': content_md,
            'content_html': content_html,
            'toc_html': toc_html,
            'link': post_link,
            'footer_time_info': mod_time_cn 
        }
        
        # æ£€æŸ¥ Slug æ˜¯å¦å˜åŒ– (å½±å“åˆ—è¡¨é¡µå’Œæ—§æ–‡ä»¶æ¸…ç†)
        if old_link and old_link != post_link and not needs_full_build:
            posts_data_changed = True
            print(f"   -> [SLUG CHANGED] {os.path.basename(md_file)}. Rebuilding all list pages.")
            
        # æ”¶é›†æ ‡ç­¾ (ç”¨äºŽåˆ—è¡¨é¡µ)
        for tag_data in post.get('tags', []):
            tag_map[tag_data['name']].append(post)
            
        parsed_posts.append(post)
        
        # 5. æ›´æ–° Manifest å’Œ posts_to_build åˆ—è¡¨
        new_manifest[relative_path] = {'hash': current_hash, 'link': post_link}
        
        if needs_full_build or (old_link and old_link != post_link):
            # å¦‚æžœå†…å®¹å˜åŒ–ï¼Œæˆ–è€… Slug å˜åŒ–ï¼Œéƒ½éœ€è¦é‡æ–°ç”Ÿæˆ HTML
            posts_to_build.append(post) 
            
        # å¦‚æžœ Slug å˜åŒ–ï¼Œåˆ é™¤æ—§çš„ HTML æ–‡ä»¶
        if old_link and old_link != post_link and old_link != 'hidden' and old_link != '404.html':
             old_html_path = os.path.join(config.BUILD_DIR, old_link.strip('/'))
             if os.path.exists(old_html_path):
                os.remove(old_html_path)
                print(f"   -> [CLEANUP] Deleted old HTML file: {old_html_path}")


    # 6. æ¸…ç†è¢«åˆ é™¤çš„æºæ–‡ä»¶ï¼ˆPost Cleanup Logicï¼‰
    deleted_paths = set(old_manifest.keys()) - source_md_paths
    for deleted_path in deleted_paths:
        item = old_manifest[deleted_path]
        deleted_link = item.get('link')
        print(f"   -> [DELETED] Source file {deleted_path} removed.")
        posts_data_changed = True # æºæ–‡ä»¶åˆ é™¤ï¼Œåˆ—è¡¨é¡µå¿…é¡»é‡å»º
        
        # åˆ é™¤å¯¹åº”çš„ HTML æ–‡ä»¶ (å¦‚æžœä¸æ˜¯ç‰¹æ®Šé¡µé¢)
        if deleted_link and deleted_link != 'hidden' and deleted_link != '404.html':
            deleted_html_path = os.path.join(config.BUILD_DIR, deleted_link.strip('/'))
            if os.path.exists(deleted_html_path):
                os.remove(deleted_html_path)
                print(f"   -> [CLEANUP] Deleted post HTML file: {deleted_html_path}")
                

    # æŽ’åº (ç”¨äºŽåˆ—è¡¨é¡µå’Œ P/N å¯¼èˆª)
    final_parsed_posts = sorted(parsed_posts, key=lambda p: p['date'], reverse=True)
    
    print(f"   -> Successfully parsed {len(final_parsed_posts)} blog posts. ({len(posts_to_build)} HTML files rebuilt)")

    # -------------------------------------------------------------------------
    # 4. P/N Navigation Injection (å¿…é¡»åœ¨æ‰€æœ‰æ–‡ç« è§£æžå’ŒæŽ’åºåŽæ‰§è¡Œ)
    # -------------------------------------------------------------------------
    for i, post in enumerate(final_parsed_posts):
        prev_post_data = final_parsed_posts[i - 1] if i > 0 else None
        next_post_data = final_parsed_posts[i + 1] if i < len(final_parsed_posts) - 1 else None

        post['prev_post_nav'] = None
        if prev_post_data:
            post['prev_post_nav'] = {
                'title': prev_post_data['title'],
                'link': prev_post_data['link']
            }

        post['next_post_nav'] = None
        if next_post_data:
            post['next_post_nav'] = {
                'title': next_post_data['title'],
                'link': next_post_data['link']
            }
    # -------------------------------------------------------------------------

    # -------------------------------------------------------------
    # 5. ç”Ÿæˆ HTML (åº”ç”¨å¢žé‡é€»è¾‘)
    # -------------------------------------------------------------
    print("\n[4/4] Generating HTML...")
    
    # ä¸ºåˆ—è¡¨/é™æ€é¡µé¢ç”Ÿæˆä¸€ä¸ªé€šç”¨çš„ç½‘ç«™æž„å»ºæ—¶é—´ (UTC+8) (åŸºäºŽå½“å‰æ—¶é—´)
    now_utc = datetime.now(timezone.utc)
    now_utc8 = now_utc.astimezone(TIMEZONE_INFO)
    global_build_time_cn = f"ç½‘ç«™æž„å»ºæ—¶é—´: {now_utc8.strftime('%Y-%m-%d %H:%M:%S')} (UTC+8)"
    
    # ç”Ÿæˆæ™®é€šæ–‡ç« è¯¦æƒ…é¡µ (åªç”Ÿæˆå˜åŠ¨çš„)
    for post in posts_to_build:
        generator.generate_post_page(post) 

    # ç”Ÿæˆåˆ—è¡¨é¡µ (åº”ç”¨å¢žé‡é€»è¾‘)
    # é¦–æ¬¡æž„å»º (old_manifestä¸ºç©º) æˆ–æ–‡ç« æ•°æ®æœ‰å˜åŒ–æ—¶ï¼Œæ‰é‡å»ºåˆ—è¡¨é¡µ
    if not old_manifest or posts_data_changed:
        print("   -> [REBUILDING] Index, Archive, Tags, RSS (Post data changed)")
        
        generator.generate_index_html(final_parsed_posts, global_build_time_cn) 
        generator.generate_archive_html(final_parsed_posts, global_build_time_cn) 
        generator.generate_tags_list_html(tag_map, global_build_time_cn) 

        # ç”Ÿæˆæ ‡ç­¾é¡µ
        for tag, posts in tag_map.items():
            sorted_tag = sorted(posts, key=lambda p: p['date'], reverse=True)
            generator.generate_tag_page(tag, sorted_tag, global_build_time_cn) 

        generator.generate_robots_txt()
        
        # Sitemap å’Œ RSS ä½¿ç”¨ç»è¿‡è¿‡æ»¤å’ŒæŽ’åºçš„åˆ—è¡¨
        with open(os.path.join(config.BUILD_DIR, config.SITEMAP_FILE), 'w', encoding='utf-8') as f:
            f.write(generator.generate_sitemap(final_parsed_posts))
        with open(os.path.join(config.BUILD_DIR, config.RSS_FILE), 'w', encoding='utf-8') as f:
            f.write(generator.generate_rss(final_parsed_posts))
            
    else:
        print("   -> [SKIPPED] Index, Archive, Tags, RSS (No post data change)")

    # 6. ä¿å­˜æ–°çš„æž„å»ºæ¸…å•
    save_manifest(new_manifest)
    print("   -> Manifest file updated.")
    
    print("\nâœ… BUILD COMPLETE")

if __name__ == '__main__':
    build_site()
